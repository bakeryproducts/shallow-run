{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import gdal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "- separate cutter from tiler\n",
    "- cutter only extracts patches (from image or image-folder)\n",
    "- tiler with zoom level\n",
    "- standalone saver\n",
    "- image-folder as src\n",
    "- webserver / zmq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def poolcontext(*args, **kwargs):\n",
    "    pool = mp.Pool(*args, **kwargs)\n",
    "    yield pool\n",
    "    pool.terminate()\n",
    "    \n",
    "def mp_func(foo, args, n):\n",
    "    args_chunks = [args[i:i + n] for i in range(0, len(args), n)]\n",
    "    with poolcontext(processes=n) as pool:\n",
    "        res = pool.map(foo, args_chunks)\n",
    "    return [ri for r in res for ri in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "p = '/home/sokolov/work/tmp/aerial/data/fortBragg/fortBragg1018_1-1.tif'\n",
    "#get_stats_gdal(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_preprocessing_gdal(p, 'fortbragg', 8, block_size=(2048,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img/\n",
    "# img_0_0.ext\n",
    "# img_0_1.ext\n",
    "# img_x_y.ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zoom(w,h, base_zoom=8):\n",
    "    return max(0, int(np.ceil(np.log2(max(w,h))-base_zoom)))\n",
    "\n",
    "def dump_info_json(name, w,h):\n",
    "    d =  {\n",
    "                'width':int(w),\n",
    "                'height':int(h),\n",
    "                'max_zoom':find_zoom(w,h),\n",
    "                'tile_size':2048\n",
    "            }\n",
    "    with open(str(name), 'w') as f:\n",
    "        json.dump(d, f)\n",
    "        \n",
    "def _write_block(block, name):\n",
    "    x, y, block_data = block\n",
    "    print(name, x,y,block_data.shape, block_data.dtype)\n",
    "    t = Image.fromarray(block_data.transpose((1,2,0)))\n",
    "    t.save(f'output/{name}_{x}_{y}.png')\n",
    "    #raise NotImplementedError\n",
    "    # DO SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_gdal(name, perc_cut=1, block_size=None, num_processes=1):\n",
    "    \"\"\"[summary]\n",
    "        name (str): Image filename\n",
    "        perc_cut (int, optional): Number of percents to cut image values from. Defaults to 1.\n",
    "        block_size ((int, int)), optional): Size of reading window. Defaults to None.\n",
    "        num_processes (int, optional): Number of processes for MP via butil.common.launch_multiprocess. Defaults to 1.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Image stats, but not 100% presise (calculated on subsamples of data)\n",
    "               (global_min,     \n",
    "                global_max,\n",
    "                global_std,\n",
    "                global_mean) \n",
    "\n",
    "    \"\"\"\n",
    "    if block_size is None:\n",
    "        _, dims, *_ = get_basics_gdal(name)\n",
    "        block_size = (256, 256) if dims[0]*dims[1] > 16e6 else (32, 32)\n",
    "        \n",
    "    nXBlocks, nYBlocks = _count_blocks(name, block_size=block_size)\n",
    "    if num_processes == 1:\n",
    "        subgrid = 0, nXBlocks, 0, nYBlocks, nXBlocks, nYBlocks\n",
    "        stats = _get_stats_subgrid(name, subgrid, block_size)\n",
    "    else:\n",
    "        # subgrid size of 20x20 blocks, experimental\n",
    "        subgrids = _get_sub_grids(20, 20, nXBlocks, nYBlocks)\n",
    "        args = [(name, subgrid, block_size) for subgrid in subgrids]\n",
    "        #foo = partial(mp_func_wrapper, _get_stats_subgrid)\n",
    "        stats = mp_func(_get_stats_subgrid, args, num_processes)#launch_multiprocess(foo, args, num_cores=num_processes)\n",
    "        stats = np.array([stat_line for stat in stats for stat_line in stat])\n",
    "\n",
    "    mins, maxs = stats[:, 0], stats[:, 1]\n",
    "    stats_cliped = stats[(mins > np.percentile(mins, perc_cut)) & (maxs < np.percentile(maxs, 100-perc_cut))]\n",
    "    global_min = np.percentile(mins, perc_cut)\n",
    "    global_max = np.percentile(maxs, 100-perc_cut)\n",
    "    global_std = stats_cliped[:, 2].std()\n",
    "    global_mean = stats_cliped[:, 2].mean()\n",
    "    return global_min, global_max, global_std, global_mean\n",
    "\n",
    "def _get_stats_subgrid(name, sub_grid, block_size):\n",
    "    nx_blocks, ny_blocks = sub_grid[1], sub_grid[3]\n",
    "    total_blocks = nx_blocks * ny_blocks\n",
    "    stats = np.zeros((total_blocks, 3))\n",
    "    gen = _get_block_subgrid(name, sub_grid, block_size=block_size)\n",
    "    for i in range(total_blocks):\n",
    "        _, _, block = next(gen)\n",
    "        x_rand, y_rand = np.random.randint(0, block.shape[1]), np.random.randint(0, block.shape[2])\n",
    "        min_ = block[:3,x_rand, y_rand].min()\n",
    "        max_ = block[:3,x_rand, y_rand].max()\n",
    "        pix = block[0, x_rand, y_rand]\n",
    "        stats[i] = np.array([min_, max_, pix])\n",
    "    return stats\n",
    "\n",
    "def _process_grid_blocks(input_name, sub_grid, block_size, global_stats=None, image_processing_func=None):\n",
    "    \"\"\"  \n",
    "    Read, process and write blocks, heart and soul of stream_reader\n",
    "    \"\"\"\n",
    "    for x, y, block in _get_block_subgrid(input_name, sub_grid, block_size):\n",
    "        #block = image_processing_func(block, stats=global_stats)\n",
    "        yield x, y, block\n",
    "\n",
    "def _get_block_subgrid(input_name, sub_grid, block_size):\n",
    "    # block generator from subgrid\n",
    "    x_start, x_n, y_start, y_n, nXBlocks, nYBlocks = sub_grid\n",
    "    input_file, input_dims, *_ = get_basics_gdal(input_name)\n",
    "    nXValid, nYValid = block_size[0], block_size[1]\n",
    "    \n",
    "    for X in range(x_start, x_start + x_n):\n",
    "        if X == nXBlocks - 1:\n",
    "            nXValid = input_dims[0] - X * block_size[0]\n",
    "        # find X offset\n",
    "        myX = X * block_size[0]\n",
    "        # reset buffer size for start of Y loop\n",
    "        nYValid = block_size[1]\n",
    "        for Y in range(y_start, y_start + y_n):\n",
    "            # change the block size of the final piece\n",
    "            if Y == nYBlocks - 1:\n",
    "                nYValid = input_dims[1] - Y * block_size[1]\n",
    "            # find Y offset\n",
    "            myY = Y * block_size[1]\n",
    "            # reading data from band\n",
    "            block = input_file.ReadAsArray(xoff=myX, yoff=myY, xsize=nXValid, ysize=nYValid)\n",
    "            if block.ndim < 3:\n",
    "                # one channel image\n",
    "                block = np.expand_dims(block, 0)\n",
    "            #yield myX, myY, block\n",
    "            yield X, Y, block\n",
    "            \n",
    "            \n",
    "def image_preprocessing_gdal(input_name, \n",
    "                             output_name,\n",
    "                             num_processes=1,\n",
    "                             block_size=None,\n",
    "                             image_processing_func=None,\n",
    "                             percentile_cut=None,\n",
    "                             show_tqdm=True):\n",
    "    \"\"\" Takes image, process and saves it tile-wise with GDAL.\n",
    "    \n",
    "    Args:\n",
    "        input_name (str): input image file name\n",
    "        output_name (str): output file name to be created\n",
    "        num_processes (int): number of parallel processes for stats calculations and image processsing.\n",
    "                             None for maximum allowed by system. Defaults to 1\n",
    "\n",
    "        image_processing_func (function, optional): should take numpy array (float32, [0,1]), tuple of image stats:\n",
    "                                                    global_stats = (global_min, global_max, global_std, global_mean)\n",
    "                                                    def image_processing_func(block, stats = global_stats):\n",
    "                                                        pass\n",
    "                                                    If number of channels after processing is less then input number,\n",
    "                                                    one shoud use output_channels_override argument to specify it. \n",
    "                                                    Defaults to None.\n",
    "\n",
    "        percentile_cut (int, optional): Percentile value to cut in np.clip. Used in stats.  Defaults to 1\n",
    "        show_tqdm (bool, optional): Show tqdm progress bar\n",
    "\n",
    "        Exmp:\n",
    "                image_preprocessing_gdal(   'Fort1.tif',\n",
    "                                            'Fort1_prep.tif',\n",
    "                                            num_processes=None,\n",
    "                                            image_processing_func=prep_func,\n",
    "                                            percentile_cut=1)\n",
    "    \"\"\"\n",
    "    if block_size is None:\n",
    "        block_size = (256, 256)\n",
    "    #global_stats = get_stats_gdal(input_name, perc_cut=percentile_cut, num_processes=num_processes)\n",
    "    nXBlocks, nYBlocks = _count_blocks(input_name, block_size=block_size)\n",
    "\n",
    "    # define subgrid size : 20x20 blocks, experimental\n",
    "    sub_x_blocks, sub_y_blocks = 10, 10\n",
    "    sub_grids = _get_sub_grids(sub_x_blocks, sub_y_blocks, nXBlocks, nYBlocks)\n",
    "    r_args = [(input_name, sub_grid, block_size) for sub_grid in sub_grids]\n",
    "    \n",
    "    launch_mpq(_process_grid_blocks, r_args, _writer, (output_name, nXBlocks*nYBlocks), num_processes, show_tqdm)\n",
    "\n",
    "    _, dims, *_  = get_basics_gdal(name)\n",
    "    \n",
    "\n",
    "def clip_block(block , min_, max_):\n",
    "    block = block.astype(np.float32)\n",
    "    block = (block - min_) / (max_ - min_)\n",
    "    return np.clip(block, 0, 1)\n",
    "\n",
    "def get_basics_gdal(name):\n",
    "    \"\"\"Get basic info from image\n",
    "    Args:\n",
    "        name (str): Image filename\n",
    "    Returns:\n",
    "        tuple: (file,                   File object (<gdal dataset>)\n",
    "                dims,                   Dimensions, tuple: (1920,1024)\n",
    "                bands_count,            Number of channels, int\n",
    "                gdal_type,              Type via GDAL typage (gdal.GDT_Byte, etc)\n",
    "                dtype  ,                Type via numpy dtype\n",
    "                block_max_type_size     Max value of numpy dtype \n",
    "                )\n",
    "    \"\"\"\n",
    "    file = gdal.Open(name, gdal.GA_ReadOnly)\n",
    "    bands_count = file.RasterCount\n",
    "    g_type = gdal.GetDataTypeName(file.GetRasterBand(1).DataType)\n",
    "    dims = [file.RasterXSize, file.RasterYSize]\n",
    "    _pix = file.ReadAsArray(0, 0, 1, 1)\n",
    "    # dtype in numpy\n",
    "    #block_max_type_size, type_np = _get_block_type_max_size(_pix)\n",
    "    return file, dims, bands_count, g_type#, type_np, block_max_type_size\n",
    "\n",
    "def _count_blocks(name, block_size=(256, 256)):\n",
    "    # find total x and y blocks to be read\n",
    "    _, dims, *_  = get_basics_gdal(name)\n",
    "    nXBlocks = (int)((dims[0] + block_size[0] - 1) / block_size[0])\n",
    "    nYBlocks = (int)((dims[1] + block_size[1] - 1) / block_size[1])\n",
    "    return nXBlocks, nYBlocks\n",
    "\n",
    "def _get_sub_grids(nx_sub, ny_sub, nXBlocks, nYBlocks):\n",
    "    \"\"\" Creates list of subgrid coords and sizes from size of one subgrid and whole grid\n",
    "    \n",
    "    Args:\n",
    "        nx_sub (int): number of blocks, x\n",
    "        ny_sub (int): number of blocks, y\n",
    "        nXBlocks (int): total blocks, x\n",
    "        nYBlocks (int): total blocks, y\n",
    "    \n",
    "    Returns:\n",
    "        list: [[start_index_x, number_of_blocks_x, start_index_y, number_of_blocks_y, nXBlocks, nYBlocks],\n",
    "               ...\n",
    "               ]\n",
    "    \"\"\"\n",
    "    sub_grids = []\n",
    "    xr = nXBlocks // nx_sub + 1 if nx_sub < nXBlocks else 1\n",
    "    yr = nYBlocks // ny_sub + 1 if ny_sub < nYBlocks else 1\n",
    "    for x in range(xr):\n",
    "        x_start = nx_sub * x\n",
    "        x_n = nx_sub if x != nXBlocks // nx_sub else nXBlocks % nx_sub\n",
    "        for y in range(yr):\n",
    "            y_start = ny_sub * y\n",
    "            y_n = ny_sub if y != nYBlocks // ny_sub else nYBlocks % ny_sub\n",
    "            sub_grids.append([x_start, x_n, y_start, y_n, nXBlocks, nYBlocks])\n",
    "    return sub_grids\n",
    "\n",
    "def _reader(arg, func, queue):\n",
    "    gen = func(*arg)\n",
    "    for i in gen:\n",
    "        queue.put(i)\n",
    "\n",
    "def _writer(output_name, total_blocks, queue):\n",
    "    count = 0\n",
    "    while(count < total_blocks):\n",
    "        try:\n",
    "            _write_block(queue.get(), output_name)\n",
    "            count+=1\n",
    "            queue.task_done()\n",
    "        except mp.TimeoutError:\n",
    "            print(\"timeout, quit.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "def mp_func_wrapper(func, args):\n",
    "    return func(*args)\n",
    "    \n",
    "def get_mp_func_args(func, args, ext):\n",
    "    func_mp_args = [(arg, *ext) for arg in args]\n",
    "    func_mp = partial(mp_func_wrapper, func)\n",
    "    return func_mp, func_mp_args\n",
    "\n",
    "def launch_mpq(r_func, r_args, w_func, w_args, num_processes, show_tqdm):\n",
    "    m = mp.Manager()\n",
    "    q = m.Queue(maxsize=50)\n",
    "    if show_tqdm: pbar = tqdm(total=len(r_args))\n",
    "\n",
    "    reader_mp, reader_mp_args = get_mp_func_args(_reader, r_args, (r_func, q))\n",
    "    writer_args = *w_args, q\n",
    "\n",
    "    with mp.Pool(num_processes) as p:    \n",
    "        g = p.imap_unordered(reader_mp, reader_mp_args)\n",
    "        writer_p = mp.Process(target=w_func, args=writer_args)\n",
    "        writer_p.start()        \n",
    "        for _ in g:\n",
    "            if show_tqdm:\n",
    "                pbar.update()\n",
    "        \n",
    "        writer_p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,shrun//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
